{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import sklearn as sk\n",
    "import scipy.io\n",
    "import librosa\n",
    "import librosa.display\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    \n",
    "    \n",
    "    items = os.listdir(file_paths)\n",
    "\n",
    "    \n",
    "    #searches through the input file for any files \n",
    "    #named .wav and adds them to the list\n",
    "    \n",
    "    newlist = []\n",
    "    for names in items:\n",
    "        if names.endswith(\".wav\"):\n",
    "            newlist.append(names)\n",
    "   \n",
    "    #Loads the files found above in with librosa\n",
    "    for fp in newlist:\n",
    "        fp = os.path.join(path, fp)\n",
    "        X,sr = librosa.load(fp,500)  \n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/tim/Documents/Masters/Data/93-001-2321.ch13/'\n",
    "raw_sounds =  load_sound_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc259cffef0>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc259cffe10>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc259cfffd0>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For testing purposes at the moment, code is here to allow you to view the input data.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=500)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 1: Waveplot',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        f_ = librosa.stft(y = f, n_fft= 256, win_length= 256)\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(f_),\n",
    "                                        sr = 500,\n",
    "                                        y_axis = 'log',\n",
    "                                        hop_length = 64 )\n",
    "        #specgram(np.array(f), Fs=500, mode = 'psd')\n",
    "        plt.title(n.title())\n",
    "        #plt.colorbar(format='%+4.0f dB')\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 2: Spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 1200)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        D = librosa.logamplitude(np.abs(librosa.stft(f))**2, ref_power=np.max)\n",
    "        librosa.display.specshow(D,x_axis='time' ,y_axis='log', sr = 500)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 3: Log power spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    " \n",
    "plot_waves('minke',raw_sounds)\n",
    "plot_specgram('minke',raw_sounds)\n",
    "plot_log_power_specgram('minke',raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xtract_features(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    # stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    # chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    # mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    # contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    # tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return X, sample_rate, mfccs#chroma,mel,contrast,tonnetz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += int(window_size / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "#     features, labels = np.empty((0, 193)), np.empty(0)\n",
    "\n",
    "   \n",
    "#     for label, sub_dir in enumerate(sub_dirs):\n",
    "         \n",
    "#         items = os.listdir(os.path.join(parent_dir, sub_dir))\n",
    "#         labels = labels.itemset(label)\n",
    "    \n",
    "#         #searches through the input file for any files \n",
    "#         #named .wav and adds them to the list\n",
    "    \n",
    "#         files = []\n",
    "#         for names in items:\n",
    "            \n",
    "#             if names.endswith(\".wav\"):\n",
    "#                 #loc = os.path.join(items[1], names)\n",
    "                \n",
    "#                 files.append(names)\n",
    "               \n",
    "#                 #print(files)\n",
    "        \n",
    "                \n",
    "#         for fn in files:\n",
    "            \n",
    "#             file = os.path.join(parent_dir, sub_dir, fn)\n",
    "            \n",
    "#             mfccs, chroma, mel, contrast,tonnetz = extract_feature(file)\n",
    "#             ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "#             features = np.vstack([features,ext_features])\n",
    "        \n",
    "\n",
    "        \n",
    "#     return np.array(features), np.array(labels, dtype = np.float)\n",
    "\n",
    "\n",
    "\n",
    "# def load_data(data_directory):\n",
    "#     \n",
    "#     \"\"\"\n",
    "#     Returns the features and labels of the wave data. \n",
    "#     \"\"\"\n",
    "#     directories = [d for d in os.listdir(data_directory) \n",
    "#                    if os.path.isdir(os.path.join(data_directory, d))]\n",
    "# \n",
    "#     features, labels = np.empty((0, 193)), []\n",
    "#     for d in directories:\n",
    "#         label_directory = os.path.join(data_directory, d)\n",
    "#         file_names = [os.path.join(label_directory, f) \n",
    "#                       for f in os.listdir(label_directory) \n",
    "#                       if f.endswith(\".wav\")]\n",
    "#         \n",
    "#         for f in file_names:\n",
    "# #             images.append(skimage.data.imread(f))\n",
    "#             X, sample_rate, mfccs = extract_feature(f)    #chroma, mel, mfccs, contrast,tonnetz - items removed for now.\n",
    "#             ext_features = np.hstack([X,mfccs])\n",
    "#             features = np.vstack([ext_features])\n",
    "#             labels.append(int(d))\n",
    "#             features = np.hstack(X, mfccs)\n",
    "#               \n",
    "#     return features, labels\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 20, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            \n",
    "            sound_clip, s = librosa.load(fn)\n",
    "            label = l\n",
    "            \n",
    "            for (start, end) in windows(sound_clip, window_size):\n",
    "\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "                    \n",
    "                    \n",
    "            mfccs.append(mfcc)\n",
    "            labels.append(l)\n",
    "            \n",
    "    features = np.asarray(mfccs).reshape(len(mfccs),frames,bands)\n",
    "    return np.array(features), np.array(labels,dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(ROOT_PATH, directory):\n",
    "\n",
    "    directories = [d for d in os.listdir(directory) \n",
    "                if os.path.isdir(os.path.join(directory, d))]\n",
    "    print(directories)\n",
    "    return directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '000', '002']\n['001', '000']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT_PATH = \"/home/tim/Documents/Masters/Data\"\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Training\")\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Testing\")\n",
    "\n",
    "train_directories = get_directories(ROOT_PATH, train_data_directory)\n",
    "test_directories = get_directories(ROOT_PATH, test_data_directory)\n",
    "\n",
    "#tr_features, tr_labels = load_data(train_data_directory)\n",
    "#ts_features, ts_labels = load_data(train_data_directory)\n",
    "\n",
    "tr_features, tr_labels = extract_features(train_data_directory, train_directories)\n",
    "#ts_features, ts_labels = extract_features(train_data_directory, test_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -7.13292548e+02   1.12164988e+02   9.56167388e+01 ...,   1.40353729e+00\n    -3.14348625e-01  -1.56968395e+00]\n  [ -7.28172562e+02   9.48400313e+01   8.75682256e+01 ...,  -1.62737606e+00\n    -3.21246989e+00  -4.44389289e+00]\n  [ -7.46813133e+02   7.05446295e+01   6.89998893e+01 ...,  -5.50471298e+00\n    -8.18252081e+00  -1.01418737e+01]\n  ..., \n  [ -3.80824829e+02   7.44225015e+01   1.92645539e+01 ...,  -1.29351992e+01\n    -8.92566559e+00   9.39881048e+00]\n  [ -3.67631709e+02   7.95271299e+01   1.75946302e+01 ...,  -7.37048186e+00\n    -5.96477118e+00   5.95703016e+00]\n  [ -3.68896627e+02   8.19653063e+01   1.45696729e+01 ...,  -2.73098220e+00\n    -3.71294718e+00   2.44771712e+00]]\n\n [[ -6.30308736e+02   1.45230027e+02   9.08733325e+01 ...,   3.23120590e+00\n     2.01090154e+00   6.11226716e-01]\n  [ -6.56504632e+02   1.22439276e+02   9.48063723e+01 ...,   2.56919242e+00\n     8.45164755e-01  -7.04985752e-01]\n  [ -7.00921161e+02   7.05381162e+01   6.91737853e+01 ...,  -2.96059018e-01\n    -3.26705027e+00  -5.61803020e+00]\n  ..., \n  [ -7.02909867e+02   6.77202760e+01   6.63404810e+01 ...,  -1.85050861e+00\n    -4.51509919e+00  -6.54677713e+00]\n  [ -6.79234482e+02   9.85041416e+01   8.97120697e+01 ...,   1.06184343e+00\n    -8.78182292e-02  -1.14026515e+00]\n  [ -6.62353800e+02   1.17817078e+02   9.79325426e+01 ...,   2.45740149e+00\n     1.63924934e+00   9.76871638e-01]]\n\n [[ -6.09326298e+02   1.90359371e+02   6.84511791e+01 ...,   2.00911173e+00\n     2.10639133e+00   1.67363008e+00]\n  [ -6.49387889e+02   1.69279766e+02   8.66334563e+01 ...,   2.49209192e+00\n     2.29100798e+00   1.64443638e+00]\n  [ -7.51248674e+02   6.88693441e+01   6.74173044e+01 ...,  -2.92572335e+00\n    -5.53051473e+00  -7.47641741e+00]\n  ..., \n  [ -7.50258566e+02   7.02763445e+01   6.88440218e+01 ...,  -1.89597854e+00\n    -4.65631904e+00  -6.75925533e+00]\n  [ -6.40530798e+02   1.74777434e+02   8.32174849e+01 ...,   1.54946904e+00\n     8.05769113e-01  -3.92732493e-01]\n  [ -5.99771520e+02   1.93189219e+02   6.25183202e+01 ...,  -5.77085838e-01\n    -8.54617348e-01  -1.67659523e+00]]\n\n ..., \n [[ -5.08621184e+02   1.99017799e+02   5.73678466e+01 ...,  -1.84230720e+00\n    -2.53657039e+00  -2.37344849e+00]\n  [ -5.51092610e+02   1.83165232e+02   8.00352881e+01 ...,  -1.21683769e+00\n    -2.48381386e+00  -2.99741648e+00]\n  [ -6.68543413e+02   7.72270459e+01   7.54101110e+01 ...,  -9.68041363e+00\n    -1.24377300e+01  -1.43512530e+01]\n  ..., \n  [ -6.72070948e+02   7.22540917e+01   7.04853760e+01 ...,  -8.17464694e+00\n    -1.03414468e+01  -1.17285208e+01]\n  [ -5.69807955e+02   1.71788608e+02   8.70533600e+01 ...,  -1.60387830e+00\n    -2.00106668e+00  -2.89911825e+00]\n  [ -5.29028627e+02   1.93239339e+02   6.93895010e+01 ...,  -9.48672318e-01\n    -1.08755101e+00  -1.85708213e+00]]\n\n [[ -7.13934751e+02   9.89881216e+01   8.49459054e+01 ...,  -8.70741069e-01\n    -3.60461214e+00  -5.63548426e+00]\n  [ -7.25898912e+02   8.56556944e+01   8.05584208e+01 ...,  -2.89541529e+00\n    -5.52230206e+00  -7.46023972e+00]\n  [ -7.35051169e+02   7.39654013e+01   7.23243739e+01 ...,  -4.80972796e+00\n    -7.36844019e+00  -9.17620222e+00]\n  ..., \n  [ -3.22224652e+02   7.57634611e+01   2.48357950e+01 ...,  -1.89675726e+01\n    -1.19211828e+01   1.16941751e+01]\n  [ -3.10371435e+02   8.09783974e+01   2.05483843e+01 ...,  -1.35995362e+01\n    -1.05628078e+01   7.08812203e+00]\n  [ -3.07720380e+02   8.20401144e+01   2.08500272e+01 ...,  -1.18685462e+01\n    -1.10477816e+01   3.88697008e+00]]\n\n [[ -5.69729945e+02   1.70242179e+02   7.82830343e+01 ...,  -1.31026871e+00\n    -1.72741914e+00  -2.62805472e+00]\n  [ -6.03558115e+02   1.47393585e+02   9.14724937e+01 ...,  -2.60109411e-01\n    -1.27763008e+00  -2.46844829e+00]\n  [ -6.79398820e+02   6.60043926e+01   6.46334204e+01 ...,  -4.13421441e+00\n    -6.93050617e+00  -9.09235281e+00]\n  ..., \n  [ -6.80068403e+02   6.50821941e+01   6.37850081e+01 ...,  -7.50223853e-01\n    -3.36788175e+00  -5.40757298e+00]\n  [ -6.08070258e+02   1.45185071e+02   9.63262090e+01 ...,   8.34065084e-02\n    -3.07939043e-01  -1.05697739e+00]\n  [ -5.74957049e+02   1.70096345e+02   8.71971921e+01 ...,  -1.88588626e+00\n    -1.96333600e+00  -2.39532929e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(tr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    print('labels ', n_labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    print('unique labels ', n_unique_labels)\n",
    "    one_hot_encode = np.eye(n_unique_labels)\n",
    "    print('one Hot', one_hot_encode)\n",
    "    \n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels  311\nunique labels  2\none Hot [[ 1.  0.]\n [ 0.  1.]]\n[[ 1.  0.]\n [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# This stuff needs to be moved from above to clean up the code. \n",
    "# ROOT_PATH = \"/home/tim/Documents/Masters/Data\"\n",
    "# train_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Training\")\n",
    "# test_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Testing\")\n",
    "\n",
    "# tr_features, tr_labels = load_data(train_data_directory)\n",
    "# ts_features, ts_labels = load_data(train_data_directory)\n",
    "\n",
    "tr_labels = one_hot_encode(tr_labels)\n",
    "#ts_labels = one_hot_encode(ts_labels)\n",
    "print(tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000\n",
    "batch_size = 50\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 20\n",
    "number_of_layers = 2\n",
    "n_steps = 41\n",
    "n_hidden = 300\n",
    "n_classes = 2 \n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name= 'x')\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name = 'y')\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(n_hidden,state_is_tuple = True):\n",
    "  return tf.contrib.rnn.BasicLSTMCell(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weight, bias, number_of_layers):\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "    [lstm_cell(n_hidden,state_is_tuple = True) for _ in range(number_of_layers)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, x, dtype = tf.float32)\n",
    "    output = tf.transpose(output, [1, 0, 2])\n",
    "    last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    return tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "prediction = RNN(x, weight, bias, number_of_layers)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_f = -tf.reduce_sum(y * tf.log(prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of batch_x 1\nlength of y 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 50, 41, 20) for Tensor 'x:0', which has shape '(?, 41, 20)'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-86f7ee8f7e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length of y'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 50, 41, 20) for Tensor 'x:0', which has shape '(?, 41, 20)'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for itr in range(training_iters):    \n",
    "        offset = (itr *  batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        batch_x = tr_features[None, offset:(offset + batch_size), :]\n",
    "        print('length of batch_x' , len(batch_x))\n",
    "        batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "        print('length of y' , len(batch_y))\n",
    "        _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "            \n",
    "        if itr % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "            print (\"Iter \" + str(itr) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    \n",
    "    print('Test accuracy: ',round(session.run(accuracy, feed_dict={x: ts_features, y: ts_labels}) , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n\nCaused by op 'gradients/mul_grad/BroadcastGradientArgs', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 5, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 663, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 395, in _broadcast_gradient_args\n    name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'mul', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 4, in <module>\n    loss_f = -tf.reduce_sum(y * tf.log(prediction))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 838, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1061, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1377, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e3533291f2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n\nCaused by op 'gradients/mul_grad/BroadcastGradientArgs', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 5, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 663, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 395, in _broadcast_gradient_args\n    name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'mul', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 4, in <module>\n    loss_f = -tf.reduce_sum(y * tf.log(prediction))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 838, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1061, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1377, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for itr in range(training_iters):    \n",
    "        offset = (itr * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        batch_x = tr_features[offset:(offset + batch_size), :, :]\n",
    "        batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "        _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "            \n",
    "        if itr % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "            print (\"Iter \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    \n",
    "    print('Test accuracy: ',round(session.run(accuracy, feed_dict={x: ts_features, y: ts_labels}) , 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
