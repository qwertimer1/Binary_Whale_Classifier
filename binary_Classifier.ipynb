{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import sklearn as sk\n",
    "import scipy.io\n",
    "import librosa\n",
    "import librosa.display\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    \n",
    "    \n",
    "    items = os.listdir(file_paths)\n",
    "\n",
    "    \n",
    "    #searches through the input file for any files \n",
    "    #named .wav and adds them to the list\n",
    "    \n",
    "    newlist = []\n",
    "    for names in items:\n",
    "        if names.endswith(\".wav\"):\n",
    "            newlist.append(names)\n",
    "   \n",
    "    #Loads the files found above in with librosa\n",
    "    for fp in newlist:\n",
    "        fp = os.path.join(path, fp)\n",
    "        X,sr = librosa.load(fp,500)  \n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/tim/Documents/Masters/Data/93-001-2321.ch13/'\n",
    "raw_sounds =  load_sound_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc259cffef0>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc259cffe10>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc259cfffd0>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For testing purposes at the moment, code is here to allow you to view the input data.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=500)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 1: Waveplot',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        f_ = librosa.stft(y = f, n_fft= 256, win_length= 256)\n",
    "        librosa.display.specshow(librosa.amplitude_to_db(f_),\n",
    "                                        sr = 500,\n",
    "                                        y_axis = 'log',\n",
    "                                        hop_length = 64 )\n",
    "        #specgram(np.array(f), Fs=500, mode = 'psd')\n",
    "        plt.title(n.title())\n",
    "        #plt.colorbar(format='%+4.0f dB')\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 2: Spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 1200)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        D = librosa.logamplitude(np.abs(librosa.stft(f))**2, ref_power=np.max)\n",
    "        librosa.display.specshow(D,x_axis='time' ,y_axis='log', sr = 500)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 3: Log power spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    " \n",
    "plot_waves('minke',raw_sounds)\n",
    "plot_specgram('minke',raw_sounds)\n",
    "plot_log_power_specgram('minke',raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    #chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    #mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    #contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    #tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return X, sample_rate, mfccs#chroma,mel,contrast,tonnetz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += int(window_size / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "#     features, labels = np.empty((0, 193)), np.empty(0)\n",
    "\n",
    "   \n",
    "#     for label, sub_dir in enumerate(sub_dirs):\n",
    "         \n",
    "#         items = os.listdir(os.path.join(parent_dir, sub_dir))\n",
    "#         labels = labels.itemset(label)\n",
    "    \n",
    "#         #searches through the input file for any files \n",
    "#         #named .wav and adds them to the list\n",
    "    \n",
    "#         files = []\n",
    "#         for names in items:\n",
    "            \n",
    "#             if names.endswith(\".wav\"):\n",
    "#                 #loc = os.path.join(items[1], names)\n",
    "                \n",
    "#                 files.append(names)\n",
    "               \n",
    "#                 #print(files)\n",
    "        \n",
    "                \n",
    "#         for fn in files:\n",
    "            \n",
    "#             file = os.path.join(parent_dir, sub_dir, fn)\n",
    "            \n",
    "#             mfccs, chroma, mel, contrast,tonnetz = extract_feature(file)\n",
    "#             ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "#             features = np.vstack([features,ext_features])\n",
    "        \n",
    "\n",
    "        \n",
    "#     return np.array(features), np.array(labels, dtype = np.float)\n",
    "\n",
    "\n",
    "\n",
    "# def load_data(data_directory):\n",
    "#     \n",
    "#     \"\"\"\n",
    "#     Returns the features and labels of the wave data. \n",
    "#     \"\"\"\n",
    "#     directories = [d for d in os.listdir(data_directory) \n",
    "#                    if os.path.isdir(os.path.join(data_directory, d))]\n",
    "# \n",
    "#     features, labels = np.empty((0, 193)), []\n",
    "#     for d in directories:\n",
    "#         label_directory = os.path.join(data_directory, d)\n",
    "#         file_names = [os.path.join(label_directory, f) \n",
    "#                       for f in os.listdir(label_directory) \n",
    "#                       if f.endswith(\".wav\")]\n",
    "#         \n",
    "#         for f in file_names:\n",
    "# #             images.append(skimage.data.imread(f))\n",
    "#             X, sample_rate, mfccs = extract_feature(f)    #chroma, mel, mfccs, contrast,tonnetz - items removed for now.\n",
    "#             ext_features = np.hstack([X,mfccs])\n",
    "#             features = np.vstack([ext_features])\n",
    "#             labels.append(int(d))\n",
    "#             features = np.hstack(X, mfccs)\n",
    "#               \n",
    "#     return features, labels\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 20, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "\n",
    "    mfccs = []\n",
    "    labels = []\n",
    "\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        \n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            \n",
    "            sound_clip, s = librosa.load(fn)\n",
    "            label = l\n",
    "            \n",
    "            for (start, end) in windows(sound_clip, window_size):\n",
    "\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "                    mfccs.append(mfcc)\n",
    "                    labels.append(label)         \n",
    "    features = np.asarray(mfccs).reshape(len(mfccs),frames,bands)\n",
    "    return np.array(features), np.array(labels,dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(ROOT_PATH, directory):\n",
    "\n",
    "    directories = [d for d in os.listdir(directory) \n",
    "                if os.path.isdir(os.path.join(directory, d))]\n",
    "    print(directories)\n",
    "    return directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '000', '002']\n['001', '000']\n20480\n['001', '000', '002']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ROOT_PATH = \"/home/tim/Documents/Masters/Data\"\n",
    "train_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Training\")\n",
    "test_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Testing\")\n",
    "\n",
    "train_directories = get_directories(ROOT_PATH, train_data_directory)\n",
    "test_directories = get_directories(ROOT_PATH, test_data_directory)\n",
    "\n",
    "#tr_features, tr_labels = load_data(train_data_directory)\n",
    "#ts_features, ts_labels = load_data(train_data_directory)\n",
    "\n",
    "tr_features, tr_labels = extract_features(train_data_directory, train_directories)\n",
    "#ts_features, ts_labels = extract_features(train_data_directory, test_directories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -6.33599509e+02   1.63328188e+02   7.74668508e+01 ...,   4.32764929e+00\n     4.19227774e+00   3.31725863e+00]\n  [ -6.63992239e+02   1.43559778e+02   9.25532866e+01 ...,   2.32071750e+00\n     1.50304815e+00   2.30788872e-01]\n  [ -7.29013189e+02   7.45636007e+01   7.28630575e+01 ...,  -7.09248750e+00\n    -9.74986211e+00  -1.16289016e+01]\n  ..., \n  [ -7.32994500e+02   6.90056216e+01   6.75202209e+01 ...,  -2.58279776e+00\n    -4.95425237e+00  -6.65036992e+00]\n  [ -6.81462055e+02   1.28940600e+02   9.67135580e+01 ...,   7.08909252e-01\n    -5.37511813e-01  -1.32880500e+00]\n  [ -6.52693318e+02   1.54232969e+02   9.39386972e+01 ...,   2.10378674e-01\n    -6.98548065e-01  -1.37886549e+00]]\n\n [[ -6.62885641e+02   1.29182642e+02   9.72616213e+01 ...,   2.21115043e+00\n     1.28083189e+00   6.93114484e-01]\n  [ -6.82325950e+02   1.09364024e+02   9.45133528e+01 ...,   1.22745833e+00\n    -9.30089423e-02  -9.26530290e-01]\n  [ -7.11987698e+02   7.24798193e+01   7.09682979e+01 ...,  -3.29863108e+00\n    -6.14401349e+00  -8.29211101e+00]\n  ..., \n  [ -7.17097455e+02   6.52946348e+01   6.39057671e+01 ...,  -2.98566729e+00\n    -5.44128901e+00  -7.27602957e+00]\n  [ -6.63825351e+02   1.26394269e+02   9.18662108e+01 ...,   2.96305566e+00\n     1.56074529e+00   7.81432302e-01]\n  [ -6.34531140e+02   1.51036326e+02   8.69722584e+01 ...,   3.94757955e+00\n     2.72121949e+00   2.15022442e+00]]\n\n [[ -6.43872006e+02   1.46460865e+02   9.63079400e+01 ...,  -1.98835856e-01\n    -4.65513297e-01  -1.13042825e+00]\n  [ -6.70451167e+02   1.21519007e+02   9.61046745e+01 ...,   7.40118916e-01\n    -4.27422534e-02  -1.00016826e+00]\n  [ -7.17214347e+02   6.51442770e+01   6.37993087e+01 ...,  -2.51675897e+00\n    -5.08077382e+00  -7.02288241e+00]\n  ..., \n  [ -7.13399124e+02   7.04830808e+01   6.89700352e+01 ...,  -3.86609311e+00\n    -6.51589263e+00  -8.48100426e+00]\n  [ -6.82139085e+02   1.09481507e+02   9.43033966e+01 ...,  -6.66359554e-01\n    -2.33833706e+00  -3.49108017e+00]\n  [ -6.62507506e+02   1.29310168e+02   9.66135855e+01 ...,  -1.88139489e+00\n    -3.40061821e+00  -4.44800612e+00]]\n\n ..., \n [[ -5.59916729e+02   1.87551353e+02   7.27977867e+01 ...,   4.14908042e+00\n     3.38158225e+00   2.90563208e+00]\n  [ -6.00482164e+02   1.63339578e+02   8.75710939e+01 ...,   3.90664395e+00\n     3.04875588e+00   2.37911303e+00]\n  [ -6.95258249e+02   6.82484643e+01   6.69081607e+01 ...,  -1.06917649e+00\n    -3.93085153e+00  -6.17819866e+00]\n  ..., \n  [ -6.93147174e+02   7.12130438e+01   6.98105099e+01 ...,  -1.28036928e+00\n    -4.26695430e+00  -6.60953186e+00]\n  [ -6.10594520e+02   1.57750641e+02   9.46876786e+01 ...,   1.97535453e+00\n     5.12032225e-01  -3.79401166e-01]\n  [ -5.74832381e+02   1.80748216e+02   8.04881494e+01 ...,   1.46208325e+00\n     3.64678472e-01  -2.99425981e-01]]\n\n [[ -6.04378094e+02   1.45865268e+02   8.61241397e+01 ...,   2.87362087e+00\n     1.18173773e+00  -1.11963665e-01]\n  [ -6.31945934e+02   1.22714256e+02   9.15186421e+01 ...,   1.58649374e+00\n    -4.90432078e-01  -2.03387109e+00]\n  [ -6.80259985e+02   6.70517513e+01   6.56777740e+01 ...,  -3.11246615e+00\n    -5.92256928e+00  -8.10778688e+00]\n  ..., \n  [ -6.76843282e+02   7.17930803e+01   7.01522446e+01 ...,  -3.63409441e+00\n    -5.78357035e+00  -7.22291798e+00]\n  [ -5.87842626e+02   1.61871234e+02   9.04386714e+01 ...,   1.34277688e+00\n     3.18674585e-01  -3.37037003e-03]\n  [ -5.48837474e+02   1.85829953e+02   7.60007231e+01 ...,   2.11624963e+00\n     1.04192388e+00   8.14536507e-01]]\n\n [[ -5.69729945e+02   1.70242179e+02   7.82830343e+01 ...,  -1.31026871e+00\n    -1.72741914e+00  -2.62805472e+00]\n  [ -6.03558115e+02   1.47393585e+02   9.14724937e+01 ...,  -2.60109411e-01\n    -1.27763008e+00  -2.46844829e+00]\n  [ -6.79398820e+02   6.60043926e+01   6.46334204e+01 ...,  -4.13421441e+00\n    -6.93050617e+00  -9.09235281e+00]\n  ..., \n  [ -6.80068403e+02   6.50821941e+01   6.37850081e+01 ...,  -7.50223853e-01\n    -3.36788175e+00  -5.40757298e+00]\n  [ -6.08070258e+02   1.45185071e+02   9.63262090e+01 ...,   8.34065084e-02\n    -3.07939043e-01  -1.05697739e+00]\n  [ -5.74957049e+02   1.70096345e+02   8.71971921e+01 ...,  -1.88588626e+00\n    -1.96333600e+00  -2.39532929e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(tr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    print('labels ', n_labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    print('unique labels ', n_unique_labels)\n",
    "    one_hot_encode = np.eye(n_unique_labels)\n",
    "    print('one Hot', one_hot_encode)\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels  19666\nunique labels  2\none Hot [[ 1.  0.]\n [ 0.  1.]]\n[[ 1.  0.]\n [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# This stuff needs to be moved from above to clean up the code. \n",
    "# ROOT_PATH = \"/home/tim/Documents/Masters/Data\"\n",
    "# train_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Training\")\n",
    "# test_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Testing\")\n",
    "\n",
    "# tr_features, tr_labels = load_data(train_data_directory)\n",
    "# ts_features, ts_labels = load_data(train_data_directory)\n",
    "\n",
    "tr_labels = one_hot_encode(tr_labels)\n",
    "#ts_labels = one_hot_encode(ts_labels)\n",
    "print(tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000\n",
    "batch_size = 50\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 20\n",
    "number_of_layers = 2\n",
    "n_steps = 41\n",
    "n_hidden = 300\n",
    "n_classes = 2 \n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name= 'x')\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name = 'y')\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(n_hidden,state_is_tuple = True):\n",
    "  return tf.contrib.rnn.BasicLSTMCell(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weight, bias, number_of_layers):\n",
    "    \n",
    "    cell = tf.contrib.rnn.MultiRNNCell(\n",
    "    [lstm_cell(n_hidden,state_is_tuple = True) for _ in range(number_of_layers)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, x, dtype = tf.float32)\n",
    "    output = tf.transpose(output, [1, 0, 2])\n",
    "    last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    return tf.nn.softmax(tf.matmul(last, weight) + bias)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "prediction = RNN(x, weight, bias, number_of_layers)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_f = -tf.reduce_sum(y * tf.log(prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of batch_x 1\nlength of y 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 50, 41, 20) for Tensor 'x:0', which has shape '(?, 41, 20)'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-461a807f08f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length of y'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 50, 41, 20) for Tensor 'x:0', which has shape '(?, 41, 20)'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for itr in range(training_iters):    \n",
    "        offset = (itr *  batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        batch_x = tr_features[None ,offset:(offset + batch_size), :]\n",
    "        print('length of batch_x' , len(batch_x))\n",
    "        batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "        print('length of y' , len(batch_y))\n",
    "        _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "            \n",
    "        if itr % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "            print (\"Iter \" + str(itr) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    \n",
    "    print('Test accuracy: ',round(session.run(accuracy, feed_dict={x: ts_features, y: ts_labels}) , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n\nCaused by op 'gradients/mul_grad/BroadcastGradientArgs', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 5, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 663, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 395, in _broadcast_gradient_args\n    name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'mul', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 4, in <module>\n    loss_f = -tf.reduce_sum(y * tf.log(prediction))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 838, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1061, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1377, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e3533291f2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n\nCaused by op 'gradients/mul_grad/BroadcastGradientArgs', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 5, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 346, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\", line 540, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py\", line 663, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 395, in _broadcast_gradient_args\n    name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'mul', defined at:\n  File \"/home/tim/anaconda3/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 18 identical lines from previous traceback]\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-61bd6d811072>\", line 4, in <module>\n    loss_f = -tf.reduce_sum(y * tf.log(prediction))\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 838, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1061, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1377, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/tim/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [2,2] vs. [50,2]\n\t [[Node: gradients/mul_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/mul_grad/Shape, gradients/mul_grad/Shape_1)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for itr in range(training_iters):    \n",
    "        offset = (itr * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        batch_x = tr_features[offset:(offset + batch_size), :, :]\n",
    "        batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "        _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "            \n",
    "        if itr % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "            print (\"Iter \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "    \n",
    "    print('Test accuracy: ',round(session.run(accuracy, feed_dict={x: ts_features, y: ts_labels}) , 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
