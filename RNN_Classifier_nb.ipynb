{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#System Imports\n",
    "import os\n",
    "import glob\n",
    "import dill as pickle\n",
    "\n",
    "\n",
    "\n",
    "#Math Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import sklearn as sk\n",
    "\n",
    "\n",
    "\n",
    "#Data Analysis Imports\n",
    "import scipy.io\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "\n",
    "#NN Import\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils as util\n",
    "\n",
    "util_class = util.utils_cls()\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories(ROOT_PATH, directory):\n",
    "\n",
    "    directories = [d for d in os.listdir(directory)\n",
    "                if os.path.isdir(os.path.join(directory, d))]\n",
    "\n",
    "    return directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_sound_wave(parent_dir, sub_dirs, file_ext=\"*.wav\"):\n",
    "        \"\"\"\n",
    "        load_sound_wave extracts from the list the amplitude of the audio signal(x)\n",
    "        and the sampling rate\n",
    "        :param parent_dir: Location of Whale data for import\n",
    "        sub_dirs\n",
    "        file_ext=\"*.wav\"\n",
    "        :return: x: Audio Signal\n",
    "                 sr: Sampling Rate\n",
    "        \"\"\"\n",
    "\n",
    "        for l, sub_dir in enumerate(sub_dirs):\n",
    "\n",
    "            for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "                sound_clip, sr = librosa.load(fn, sr = None)\n",
    "\n",
    "                S = pd.Series(sound_clip, name = fn, )\n",
    "            print (S)\n",
    "            label = l\n",
    "            df.append(S, ignore_index= True)\n",
    "            print(df)\n",
    "            # df['label'] = label\n",
    "        print(type(sound_clip  ))\n",
    "        return sound_clip, sr, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data():\n",
    "    \n",
    "    if os.name == 'nt':\n",
    "        ROOT_PATH = \"D:/Masters/Data\"\n",
    "    else:\n",
    "        ROOT_PATH = \"/home/tim/Documents/Masters/Data\"\n",
    "        \n",
    "    train_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Training\")\n",
    "    test_data_directory = os.path.join(ROOT_PATH, \"Autoencoder test/Testing\")\n",
    "    print('train data directory' + str(train_data_directory))\n",
    "    print('test data directory' + str(test_data_directory))  \n",
    "    train_directories = get_directories(ROOT_PATH, train_data_directory)\n",
    "    test_directories = get_directories(ROOT_PATH, test_data_directory)\n",
    "    print('train  directories' + str(train_directories))\n",
    "\n",
    "    raw_sounds_tr, sr_tr, tr_labels = load_sound_wave(parent_dir=train_data_directory, sub_dirs=train_directories, file_ext=\"*.wav\")\n",
    "    raw_sounds_ts, sr_ts, ts_labels = load_sound_wave(parent_dir=test_data_directory, sub_dirs=test_directories, file_ext=\"*.wav\")\n",
    "    return raw_sounds_tr, raw_sounds_ts, sr_tr, sr_ts, tr_labels, ts_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data directoryD:/Masters/Data\\Autoencoder test/Training\ntest data directoryD:/Masters/Data\\Autoencoder test/Testing\ntrain  directories['Noise', 'Minke']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0.055237\n1        0.011505\n2       -0.097961\n3        0.015747\n4        0.123383\n5        0.041962\n6        0.019196\n7        0.036377\n8       -0.016785\n9        0.001953\n10       0.063721\n11       0.045410\n12       0.013275\n13       0.034485\n14       0.072723\n15       0.027344\n16      -0.055511\n17      -0.005127\n18       0.043304\n19      -0.044220\n20      -0.027130\n21       0.020844\n22      -0.121582\n23      -0.124786\n24       0.016235\n25      -0.046875\n26      -0.078278\n27       0.013214\n28      -0.039917\n29      -0.045074\n           ...   \n16176   -0.052734\n16177   -0.021545\n16178    0.023590\n16179    0.047729\n16180    0.040100\n16181    0.027527\n16182    0.002380\n16183   -0.039825\n16184   -0.024994\n16185    0.020782\n16186    0.003113\n16187   -0.021576\n16188    0.019409\n16189    0.068634\n16190    0.107941\n16191    0.073639\n16192    0.011871\n16193   -0.061615\n16194   -0.057465\n16195   -0.004791\n16196    0.020691\n16197    0.028992\n16198    0.030426\n16199    0.020386\n16200    0.025818\n16201    0.017273\n16202   -0.030518\n16203   -0.069977\n16204   -0.065308\n16205   -0.029755\nName: D:/Masters/Data\\Autoencoder test/Training\\Noise\\93-002-1442.ch12_4777.3_Noise.wav_001_Noise_.wav, Length: 16206, dtype: float32\nEmpty DataFrame\nColumns: []\nIndex: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       -0.030487\n1       -0.039978\n2       -0.052216\n3       -0.048035\n4       -0.016418\n5        0.023956\n6        0.038086\n7        0.017822\n8       -0.001007\n9       -0.014374\n10      -0.032318\n11      -0.022003\n12       0.018921\n13       0.050293\n14       0.066772\n15       0.058502\n16       0.016418\n17      -0.020844\n18      -0.037506\n19      -0.054230\n20      -0.059174\n21      -0.018311\n22       0.045319\n23       0.103577\n24       0.061737\n25       0.004669\n26      -0.036469\n27      -0.035187\n28      -0.014709\n29       0.012970\n           ...   \n20331    0.051544\n20332    0.030334\n20333   -0.027618\n20334   -0.056244\n20335   -0.054291\n20336   -0.046082\n20337   -0.028229\n20338   -0.008575\n20339    0.003143\n20340    0.019928\n20341    0.030823\n20342    0.029999\n20343    0.042725\n20344    0.035187\n20345   -0.017822\n20346   -0.044373\n20347   -0.019531\n20348   -0.011780\n20349   -0.041351\n20350   -0.043274\n20351    0.025635\n20352    0.103729\n20353    0.095673\n20354    0.024017\n20355   -0.027863\n20356   -0.054718\n20357   -0.053497\n20358   -0.007202\n20359    0.025177\n20360    0.017365\nName: D:/Masters/Data\\Autoencoder test/Training\\Minke\\93-001-2321.ch13_968.01.wav_000_Minke_.wav, Length: 20361, dtype: float32\nEmpty DataFrame\nColumns: []\nIndex: []\n<class 'numpy.ndarray'>\n0        0.000061\n1        0.013977\n2        0.015015\n3        0.027222\n4        0.027435\n5       -0.007660\n6       -0.010559\n7        0.016327\n8        0.007446\n9        0.000031\n10       0.023315\n11       0.031128\n12       0.020233\n13       0.012939\n14       0.012177\n15       0.011444\n16      -0.021790\n17      -0.072113\n18      -0.074463\n19      -0.031006\n20       0.024078\n21       0.056793\n22       0.038574\n23       0.010864\n24       0.005463\n25       0.004547\n26       0.003479\n27      -0.015839\n28      -0.054565\n29      -0.052551\n           ...   \n17376    0.007690\n17377    0.021637\n17378   -0.004059\n17379   -0.028229\n17380   -0.025024\n17381    0.005280\n17382    0.019073\n17383    0.001617\n17384   -0.006775\n17385   -0.010895\n17386   -0.019043\n17387   -0.009277\n17388    0.005402\n17389    0.012756\n17390    0.022705\n17391    0.029999\n17392    0.022308\n17393    0.010834\n17394    0.011566\n17395    0.006805\n17396   -0.000854\n17397    0.011597\n17398    0.008057\n17399   -0.014282\n17400   -0.003082\n17401    0.012909\n17402   -0.013947\n17403   -0.045624\n17404   -0.045532\n17405   -0.018799\nName: D:/Masters/Data\\Autoencoder test/Testing\\Minke\\93-001-2321.ch13_654.63.wav, Length: 17406, dtype: float32\nEmpty DataFrame\nColumns: []\nIndex: []\n0       -0.016083\n1       -0.031189\n2       -0.010406\n3       -0.025543\n4        0.011597\n5        0.012634\n6       -0.056335\n7       -0.017303\n8        0.042389\n9       -0.014282\n10      -0.040649\n11      -0.012665\n12      -0.015778\n13       0.027954\n14       0.057953\n15       0.001556\n16       0.009338\n17       0.032471\n18      -0.023499\n19      -0.003174\n20       0.046570\n21      -0.014801\n22      -0.044128\n23       0.010498\n24       0.021637\n25       0.023865\n26       0.050720\n27       0.018372\n28      -0.039764\n29      -0.048584\n           ...   \n46306   -0.024139\n46307   -0.034485\n46308   -0.025085\n46309    0.007721\n46310    0.018188\n46311   -0.009857\n46312   -0.001099\n46313    0.036987\n46314    0.033783\n46315    0.013763\n46316   -0.016205\n46317   -0.027710\n46318    0.019684\n46319    0.033997\n46320    0.010925\n46321    0.043610\n46322    0.071869\n46323    0.040039\n46324    0.036987\n46325    0.048798\n46326    0.029236\n46327    0.033966\n46328    0.012146\n46329   -0.037048\n46330   -0.000946\n46331    0.011627\n46332   -0.059174\n46333   -0.010101\n46334    0.067688\n46335   -0.031921\nName: D:/Masters/Data\\Autoencoder test/Testing\\Noise\\93-002-1442.ch12_2734.1_Noise.wav, Length: 46336, dtype: float32\nEmpty DataFrame\nColumns: []\nIndex: []\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_sounds_tr, raw_sounds_ts, sr_tr, sr_ts, tr_labels, ts_labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20361\n[-0.01608276 -0.03118896 -0.01040649 ..., -0.01010132  0.06768799\n -0.03192139]\n"
     ]
    }
   ],
   "source": [
    "str_raw_sounds_tr = str(raw_sounds_tr)\n",
    "str_raw_sounds_ts = str(raw_sounds_ts)\n",
    "print(len(raw_sounds_tr))\n",
    "\n",
    "print(str_raw_sounds_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    training_file = \"D:\\Masters\\Data/Autoencoder test/Training/training_tester.pkl\"\n",
    "    testing_file = \"D:\\Masters\\Data/Autoencoder test/Testing/testing_tester.pkl\"\n",
    "else:\n",
    "    \n",
    "    training_file = \"/home/tim/Documents/Masters/Data/Autoencoder test/Training/training_tester.pkl\"\n",
    "    testing_file = \"/home/tim/Documents/Masters/Data/Autoencoder test/Testing/testing_tester.pkl\"\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_class.DILL_pickle_files(raw_sounds_tr, training_file)\n",
    "\n",
    "util_class.DILL_pickle_files(raw_sounds_ts, testing_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_sounds_tr = util_class.DILL_unpickle_files(training_file)\n",
    "\n",
    "pickled_sounds_ts = util_class.DILL_unpickle_files(testing_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sounds_tr:0\", shape=(897921,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sounds_tr = tf.convert_to_tensor(pickled_sounds_tr, dtype=tf.float32, name='sounds_tr' )\n",
    "sounds_ts = tf.convert_to_tensor(pickled_sounds_ts, dtype=tf.float32, name='sounds_ts')\n",
    "\n",
    "\n",
    "print(sounds_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def one_hot_encode( labels):\n",
    "        n_labels = labels\n",
    "        n_unique_labels = len(np.unique(labels))\n",
    "        one_hot_encode = np.eye(n_unique_labels)\n",
    "\n",
    "        return one_hot_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RNN(x, number_of_layers, n_hidden, labels):\n",
    "    \n",
    "    init_state = tf.placeholder(tf.float32, [number_of_layers, 2, batch_size, n_hidden])\n",
    "\n",
    "    state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "    #rnn_tuple_state = tuple([tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1]) for idx in range(number_of_layers)])\n",
    "    \n",
    "    cell = tf.contrib.rnn.LSTMCell(n_hidden, state_is_tuple=True)\n",
    "    \n",
    "    #stacked_lstm = tf.contrib.rnn.MultiRNNCell([cell] * number_of_layers, state_is_tuple=True)\n",
    "    #initial_state = tf.identity(stacked_lstm.zero_state(batch_size, tf.float32), name = 'initial_state')\n",
    "    initial_state = tf.identity(cell.zero_state(batch_size, tf.float32), name = 'initial_state')\n",
    "    \n",
    "    Outputs, final_state = tf.nn.dynamic_rnn(cell, x, dtype = tf.float32)\n",
    "    final_state = tf.identity(final_state, name='final_state')\n",
    "   \n",
    "    Logits = tf.contrib.layers.fully_connected(Outputs, \n",
    "                                               num_outputs = len(labels),\n",
    "                                               activation_fn = None,\n",
    "                                              weights_initializer = (tf.truncated_normal_initializer(stddev = 0.1)),\n",
    "                                              biases_initializer = (tf.zeros_initializer()))\n",
    "    return (Logits, final_state, initial_state)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batches(sounds, batch_size, seq_length, labels):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sound_size = sounds.get_shape()\n",
    "    sound_length = int(sound_size[0])\n",
    "    print(sound_length)\n",
    "    n_batches = int(sound_length / (batch_size * seq_length))\n",
    "\n",
    "    # Drop the last few characters to make only full batches\n",
    "    xdata = np.array(sounds[: n_batches * batch_size * seq_length])\n",
    "    ydata = np.array(labels)\n",
    "\n",
    "    x_batches = np.split(xdata.reshape(batch_size, -1), n_batches, 1)\n",
    "    y_batches = ydata\n",
    "\n",
    "    return np.asarray(list(zip(x_batches, y_batches)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897921\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (50,newaxis)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6e1546664e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mbatches_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msounds_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mbatches_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msounds_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-28bf643444e9>\u001b[0m in \u001b[0;36mget_batches\u001b[0;34m(sounds, batch_size, seq_length, labels)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0my_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (50,newaxis)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#def main():\n",
    "\"\"\"\n",
    "\n",
    ":return:\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#sounds_ts = tf.convert_to_tensor(raw_sounds_ts, dtype=tf.float32, name='sounds_ts')\n",
    "######################################\n",
    "tr_labels = one_hot_encode(tr_labels)\n",
    "ts_labels = one_hot_encode(ts_labels)\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.01\n",
    "num_epochs = 1000\n",
    "batch_size = 50\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "\n",
    "number_of_layers = 2\n",
    "\n",
    "n_hidden = 300\n",
    "n_classes = 2\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 300, 1], name='x')\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "#raw_sounds_tr = tf.unstack(raw_sounds_tr)\n",
    "#raw_sounds_ts = tf.unstack(raw_sounds_ts)\n",
    "\n",
    "Logits, final_state, initial_state = RNN(x, number_of_layers, n_hidden, tr_labels)\n",
    "\n",
    "# Define loss ///and optimizer\n",
    "cost = -tf.reduce_sum(y * tf.log(Logits))\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "\n",
    "    # Gradient Clipping\n",
    "\n",
    "#capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in optimizer]\n",
    "#train_op = optimizer.apply_gradients(capped_gradients)\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(Logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "\n",
    "batches_tr = get_batches(sounds_tr, batch_size, display_step, tr_labels)\n",
    "batches_ts = get_batches(sounds_ts, batch_size, display_step, ts_labels)\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {x: batches_tr[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches_tr):\n",
    "            feed = {\n",
    "                x: batches_tr,\n",
    "                y: tr_labels,\n",
    "                initial_state: state,\n",
    "                lr: lr}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches_tr) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches_tr),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    #saver = tf.train.Saver()\n",
    "    #saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')\n",
    "    # for itr in range(training_iters):\n",
    "    #     offset = (itr * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "    #     batch_x = raw_sounds_tr\n",
    "    #     print(batch_x)\n",
    "    #     batch_x = np.squeeze(batch_x)\n",
    "    #     batch_y = tr_labels[offset:(offset + batch_size)]\n",
    "    #     _, c = session.run([optimizer, loss_f], feed_dict={x: batch_x, y: batch_y})\n",
    "    # \n",
    "    #     if itr % display_step == 0:\n",
    "    #         # Calculate batch accuracy\n",
    "    #         acc = session.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "    #         # Calculate batch loss\n",
    "    #         loss = session.run(loss_f, feed_dict={x: batch_x, y: batch_y})\n",
    "    #         print(\"Iter \" + str(epoch) + \", Minibatch Loss= \" + \\\n",
    "    #               \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "    #               \"{:.5f}\".format(acc))\n",
    "    # \n",
    "    # print('Test accuracy: ', round(session.run(accuracy, feed_dict={x: batch_x, y: ts_labels}), 3))\n",
    "    # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
